{
  "hash": "a59dc81a0e3af98d50f6977867ac06d1",
  "result": {
    "engine": "knitr",
    "markdown": "# Transformations {#sec-TRANSF}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Objectives\n\n1)  Determine the distribution of a transformed discrete random variable using appropriate methods, and use it to calculate probabilities.\n\n2)  Determine the distribution of a transformed continuous random variable using appropriate methods, and use it to calculate probabilities.\n\n3)  Determine the distribution of a transformation of multivariate random variables using simulation, and use it to calculate probabilities.\n\n## Transformations\n\nThroughout our coverage of random variables, we have mentioned transformations of random variables. These have been in the context of linear transformations. We have discussed expected value and variance of linear transformations. Recall that $\\mbox{E}(aX+b)=a\\mbox{E}(X)+b$ and $\\mbox{Var}(aX+b)=a^2\\mbox{Var}(X)$.\n\nIn this chapter, we will discuss transformations of random variables in general, beyond the linear case.\n\n### Transformations of discrete random variables\n\nLet $X$ be a discrete random variable and let $g$ be a function. The variable $Y=g(X)$ is a discrete random variable with pmf: $$\nf_Y(y)=\\mbox{P}(Y=y)=\\sum_{\\forall x: g(x)=y}\\mbox{P}(X=x)=\\sum_{\\forall x: g(x)=y}f_X(x)\n$$\n\nAn example would help since the notation can be confusing.\n\n> *Example*:\\\n> Suppose $X$ is a discrete random variable with pmf: $$\n> f_X(x)=\\left\\{\\begin{array}{ll} 0.05, & x=-2 \\\\ \n> 0.10, & x=-1 \\\\\n> 0.35, & x=0 \\\\\n> 0.30, & x=1 \\\\\n> 0.20, & x=2 \\\\\n> 0, & \\mbox{otherwise} \\end{array}\\right.\n> $$\n\nFind the pmf for $Y=X^2$.\n\nIt helps to identify the support of $Y$, that is where $f_{Y}(y)>0$. Since the support of $X$ is $S_X=\\{-2,-1,0,1,2\\}$, the support of $Y$ is $S_Y=\\{0,1,4\\}$. $$\nf_Y(0)=\\sum_{x^2=0}f_X(x)=f_X(0)=0.35\n$$\n\n$$\nf_Y(1)=\\sum_{x^2=1}f_X(x)=f_X(-1)+f_X(1)=0.1+0.3=0.4\n$$ $$\nf_Y(4)=\\sum_{x^2=4}f_X(x)=f_X(-2)+f_X(2)=0.05+0.2=0.25\n$$\n\nSo, $$\nf_Y(y)=\\left\\{\\begin{array}{ll} 0.35, & y=0 \\\\ \n0.4, & y=1 \\\\\n0.25, & y=4 \\\\\n0, & \\mbox{otherwise} \\end{array}\\right.\n$$\n\nIt also helps to confirm that these probabilities add to one, which they do. This is the pmf of $Y=X^2$.\n\nThe key idea is to find the support of the new random variable and then go back to the original random variable and sum all the probabilities that get mapped into that new support element.\n\n### Transformations of continuous random variables\n\nThe methodology above will not work directly in the case of continuous random variables. This is because in the continuous case, the pdf, $f_X(x)$, represents **density** and not **probability**.\n\n### The cdf method\n\nThe **cdf method** is one of several methods that can be used for transformations of continuous random variables. The idea is to find the cdf of the new random variable and then find the pdf by way of the fundamental theorem of calculus.\n\nSuppose $X$ is a continuous random variable with cdf $F_X(x)$. Let $Y=g(X)$. We can find the cdf of $Y$ as:\n\n$$\nF_Y(y)=\\mbox{P}(Y\\leq y)=\\mbox{P}(g(X)\\leq y)=\\mbox{P}(X\\leq g^{-1}(y))=F_X(g^{-1}(y))\n$$\n\nTo get the pdf of $Y$ we would need to take the derivative of the cdf. Note that $g^{-1}(y)$ is the function inverse while $g(y)^{-1}$ is the multiplicative inverse.\n\nThis method requires the transformation function to have an inverse. Sometimes we can break the domain of the original random variables into regions where an inverse of the transformation function exists.\n\n> *Example*: Let $X\\sim \\textsf{Unif}(0,1)$ and let $Y=X^2$. Find the pdf of $Y$.\n\nBefore we start, let's think about the distribution of $Y$. We are randomly taking numbers between 0 and 1 and then squaring them. Squaring a positive number less than 1 makes it even smaller. We thus suspect the pdf of $Y$ will have larger density near 0 than 1. The shape is hard to determine so let's do some math.\n\nSince $X$ has the uniform distribution, we know that $f_X(x)$ and $F_X(x)=x$ for $0\\leq x \\leq 1$. So, $$\nF_Y(y)=\\mbox{P}(Y\\leq y)=\\mbox{P}(X^2\\leq y)=\\mbox{P}(X\\leq \\sqrt{y})=F_X\\left(\\sqrt{y}\\right)=\\sqrt{y}\n$$\n\nTaking the derivative of this yields: $$\nf_Y(y)=\\frac{1}{2\\sqrt{y}}\n$$\n\nfor $0 < y \\leq 1$ and 0 otherwise. Notice we can't have $y=0$ since we would be dividing by zero. This is not a problem since we have a continuous distribution. We could verify this a proper pdf by determining if the pdf integrates to 1 over the domain: $$\n\\int_0^1 \\frac{1}{2\\sqrt{y}} \\,\\mathrm{d}y = \\sqrt{y}\\bigg|_0^1 = 1\n$$ We can also do this using `R` but we first have to create a function that can take vector input.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_pdf <- function(y) {\n  1/(2*sqrt(y))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ny_pdf<- Vectorize(y_pdf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nintegrate(y_pdf,0,1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1 with absolute error < 2.9e-15\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nNotice that since the domain of the original random variable was non-negative, the squared function had an inverse.\n\nThe pdf of the random variable $Y$ is plotted in @fig-pdf161.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_line(y_pdf(seq(0.01,1,.01))~seq(0.01,1,.01),xlab=\"Y\",ylab=expression(f(y))) %>%\n  gf_theme(theme_bw())\n```\n\n::: {.cell-output-display}\n![he pdf of the transformed random variable $Y$](Transformations_files/figure-html/fig-pdf161-1.png){#fig-pdf161 width=672}\n:::\n:::\n\n\n\n\n\n\n\n\nWe can see that the density is much larger at we approach 0.\n\n### The pdf method\n\nThe cdf method of transforming continuous random variables also yields to another method called the **pdf method**. Recall that the cdf method tells us that if $X$ is a continuous random variable with cdf $F_X$, and $Y=g(X)$, then\n\n$$\nF_Y(y)=F_X(g^{-1}(y))\n$$\n\nWe can find the pdf of $Y$ by differentiating the cdf: $$\nf_Y(y)=\\frac{\\,\\mathrm{d}}{\\,\\mathrm{d}y}F_Y(y)=\\frac{\\,\\mathrm{d}}{\\,\\mathrm{d}y} F_X(g^{-1}(y)) = f_X(g^{-1}(y))\\bigg| \\frac{\\,\\mathrm{d}}{\\,\\mathrm{d}y}  g^{-1}(y) \\bigg|\n$$\n\nSo, as long as $g^{-1}$ is differentiable, we can use this method to directly obtain the pdf of $Y$.\n\nNote that in some texts, the portion of this expression $\\frac{\\,\\mathrm{d}}{\\,\\mathrm{d}y} g^{-1}(y)$ is sometimes referred to as the *Jacobian*. We need to take the absolute value of the transformation function $g(x)$ because if it is a decreasing function, we have\n\n$$\nF_Y(y)=\\mbox{P}(Y\\leq y)=\\mbox{P}(g(X) \\leq y)=\\mbox{P}(X \\geq g^{-1}(y))= 1 - F_X(g^{-1}(y))\n$$\n\n> **Exercise**:\\\n> Repeat the previous example using the pdf method.\n\nSince $X$ has the uniform distribution, we know that $f_X(x)=1$ for $0\\leq x \\leq 1$. Also, $g(x)=x^2$ and $g^{-1}(y)=\\sqrt{y}$, which is differentiable. So,\n\n$$\nf_Y(y)=f_X(\\sqrt{y})\\bigg|\\frac{\\,\\mathrm{d}}{\\,\\mathrm{d}y} \\sqrt{y}\\bigg| = \\frac{1}{2\\sqrt{y}}\n$$\n\n### Simulation\n\nWe can also get an estimate of the distribution by simulating the random variable. If we have the cdf and can find its inverse, then just like we did in an earlier chapter, we sample from a uniform distribution and apply the inverse to get the distribution.\n\nIn an earlier chapter we had the example:\n\n> Let $X$ be a continuous random variable with $f_X(x)=2x$ where $0 \\leq x \\leq 1$.\n\nNow let's find an approximation to the distribution of $Y = \\ln{X}$ using simulation.\n\nThe cdf of $X$ is $F_X(x)=x^2$ where $0 \\leq x \\leq 1$. We will draw a uniform random variable and then take the square root to simulate a random variable from $f_X(x)$. We will replicate this 10,000 times. In `R` our code, which we have done before, is:\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1107)\nresults <- do(10000)*sqrt(runif(1))\n```\n:::\n\n\n\n\n\n\n\n\nRemember, we are using the square root because we want the inverse of the cdf and not, for this method, the inverse of the transformation function as when we were using the mathematical method. This can be a point of confusion.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninspect(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nquantitative variables:  \n  name   class        min        Q1    median        Q3       max      mean\n1 sqrt numeric 0.01126465 0.5027012 0.7069864 0.8670356 0.9999379 0.6672924\n         sd     n missing\n1 0.2341494 10000       0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n@fig-dens161 is a density plot of the simulated original random variable.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults %>%\n  gf_density(~sqrt,xlab=\"X\") %>%\n  gf_theme(theme_bw()) %>%\n  gf_labs(y=\"\")\n```\n\n::: {.cell-output-display}\n![The density plot of the original using simulation.](Transformations_files/figure-html/fig-dens161-1.png){#fig-dens161 width=672}\n:::\n:::\n\n\n\n\n\n\n\n\nNow to find the distribution of $Y$ we just apply the transformation.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_results <- results %>%\n  transmute(y=log(sqrt))\n```\n:::\n\n\n\n\n\n\n\n\n@fig-dens162 is the density plot of the transformed random variable from the simulation. We can see that the support for $Y$ is $-\\infty < y \\leq 0$ and the density is tight near zero but skewed to the left.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_results %>%\n  gf_density(~y,xlab=\"X\")  %>%\n  gf_theme(theme_bw()) %>%\n  gf_labs(y=\"\")\n```\n\n::: {.cell-output-display}\n![The density plot of the transformed random variable from the simulation.](Transformations_files/figure-html/fig-dens162-1.png){#fig-dens162 width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninspect(y_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nquantitative variables:  \n  name   class       min         Q1     median         Q3           max\n1    y numeric -4.486086 -0.6877593 -0.3467439 -0.1426753 -6.207173e-05\n        mean        sd     n missing\n1 -0.4969103 0.4933701 10000       0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n### Multivariate Transformations\n\nFor the discrete case, if you have the joint pmf, then if the transformation is to a univariate random variable, the process is similar to what see learned above. For continuous random variables, the mathematics are a little more difficult so we will just use simulation.\n\nHere's the scenario. Suppose $X$ and $Y$ are independent random variables, both uniformly distributed on $[5,6]$. $$\nX\\sim \\textsf{Unif}(5,6)\\hspace{1.5cm} Y\\sim \\textsf{Unif}(5,6)\n$$\n\nLet $X$ be your arrival time for dinner and $Y$ your friends arrival time. We picked 5 to 6 because this is the time in the evening we want to meet. Also assume you both travel independently.\n\nDefine $Z$ as a transformation of $X$ and $Y$ such that $Z=|X-Y|$. Thus $Z$ is the absolute value of the difference between your arrival times. The units for $Z$ are hours. We would like to explore the distribution of $Z$. We could do this via calc III methods but we will simulate instead.\n\nWe can use `R` to obtain simulated values from $X$ and $Y$ (and thus find $Z$).\n\nFirst, simulate 100,000 observations from the uniform distribution with parameters 5 and 6. Assign those random observations to a variable. Next, repeat that process, assigning those to a different variable. These two vectors represent your simulated values from $X$ and $Y$. Finally, obtain your simulated values of $Z$ by taking the absolute value of the difference.\n\n> **Exercise**:\n\nComplete the code on your own before looking at the code below.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(354)\nresults <- do(100000)*abs(diff(runif(2,5,6)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         abs\n1 0.03171229\n2 0.77846706\n3 0.29111599\n4 0.06700434\n5 0.08663187\n6 0.40622840\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n@fig-dens163 is a plot of the estimated density of the transformation.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults %>%\n  gf_density(~abs) %>%\n  gf_theme(theme_bw()) %>%\n  gf_labs(x=\"|X-Y|\",y=\"\")\n```\n\n::: {.cell-output-display}\n![The density of the absolute value of the difference in uniform random variables.](Transformations_files/figure-html/fig-dens163-1.png){#fig-dens163 width=672}\n:::\n:::\n\n\n\n\n\n\n\n\nOr as a histogram in @fig-hist163 .\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults %>%\n  gf_histogram(~abs)%>%\n  gf_theme(theme_bw()) %>%\n  gf_labs(x=\"|X-Y|\",y=\"\")\n```\n\n::: {.cell-output-display}\n![Histogram of the absolute value of the difference in random variables.](Transformations_files/figure-html/fig-hist163-1.png){#fig-hist163 width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninspect(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nquantitative variables:  \n  name   class          min       Q1    median        Q3       max     mean\n1  abs numeric 1.265667e-06 0.133499 0.2916012 0.4990543 0.9979459 0.332799\n         sd      n missing\n1 0.2358863 100000       0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n> **Exercise**:\\\n> Now suppose whomever arrives first will only wait 5 minutes and then leave. What is the probability you eat together?\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(results) %>%\n  summarise(mean(abs<=5/60))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mean(abs <= 5/60)\n1           0.15966\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n> **Exercise**:\\\n> How long should the first person wait so that there is at least a 50% probability of you eating together?\n\nLet's write a function to find the cdf.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz_cdf <- function(x) {\n  mean(results$abs<=x)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nz_cdf<- Vectorize(z_cdf)\n```\n:::\n\n\n\n\n\n\n\n\nNow test for 5 minutes to make sure our function is correct since we determined above that this value should be 0.15966.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz_cdf(5/60)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.15966\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nLet's plot to see what the cdf looks like.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_line(z_cdf(seq(0,1,.01))~seq(0,1,.01),xlab=\"Time Difference\",ylab=\"CDF\") %>%\n  gf_theme(theme_bw())\n```\n\n::: {.cell-output-display}\n![](Transformations_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\nIt looks like somewhere around 15 minutes, a quarter of an hour. But we will find a better answer by finding the root. In the code that follows we want to find where the cdf equals 0.5. The function `uniroot()` solves the given equations for roots so we want to put in the cdf minus 0.5. In other words, `uniroot()` solves $f(x)=0$ for x.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuniroot(function(x)z_cdf(x)-.5,c(.25,35))$root\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2916077\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nSo it is actually 0.292 hours, 17.5 minutes. So round up and wait 18 minutes.\n",
    "supporting": [
      "Transformations_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}