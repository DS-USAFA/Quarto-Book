# Overview of Data Collection Principles {#sec-ODCP}

```{r}
#| echo: false
#| message: false
#| warning: false

library(kableExtra)
library(openintro)
library(tidyverse)
library(mosaic)
```

## Objectives

1)  Differentiate between various statistical terminologies such as *population, sample, anecdotal evidence, bias, simple random sample, systematic sample, representative sample, non-response bias, convenience sample, explanatory variable,* *response variable, observational study, cohort, experiment, randomized experiment,* and *placebo*, and construct examples to demonstrate their proper use in context.

2)  Evaluate descriptions of research project to identify the population of interest, assess the generalizability of the study, determine the explanatory and response variables, classify the study as observational or experimental, and determine the type of sample used.

3)  Design and justify sampling procedures for various research contexts, comparing the strengths and weaknesses of different sampling methods (simple random, systematic, convenience, etc.) and proposing improvements to minimize bias and enhance representativeness.

## Overview of data collection principles

The first step in conducting research is to identify topics or questions that are to be investigated. A clearly laid out research question is helpful in identifying what subjects or cases should be studied and what variables are important. It is also important to consider *how* data are collected so that they are reliable and help achieve the research goals.

### Populations and samples

Consider the following three research questions:

1.  What is the average mercury content in swordfish in the Atlantic Ocean?\
2.  Over the last 5 years, what is the average time to complete a degree for Duke undergraduate students?\
3.  Does a new drug reduce the number of deaths in patients with severe heart disease?

Each research question refers to a target **population**, the entire collection of individuals about which we want information. In the first question, the target population is all swordfish in the Atlantic Ocean, and each fish represents a case. It is usually too expensive to collect data for every case in a population. Instead, a sample is taken. A **sample** represents a subset of the cases and is often a small fraction of the population. For instance, 60 swordfish (or some other number) in the population might be selected, and this sample data may be used to provide an estimate of the population average and answer the research question.

> **Exercise**:\
> For the second and third questions above, identify the target population and what represents an individual case.[^overview-of-data-collection-principles-1]

[^overview-of-data-collection-principles-1]: 2\) Notice that the second question is only relevant to students who complete their degree; the average cannot be computed using a student who never finished her degree. Thus, only Duke undergraduate students who have graduated in the last five years represent cases in the population under consideration. Each such student would represent an individual case. 3) A person with severe heart disease represents a case. The population includes all people with severe heart disease.

### Anecdotal evidence

Consider the following possible responses to the three research questions:

1.  A man on the news got mercury poisoning from eating swordfish, so the average mercury concentration in swordfish must be dangerously high.
2.  I met two students who took more than 7 years to graduate from Duke, so it must take longer to graduate at Duke than at many other colleges.
3.  My friend's dad had a heart attack and died after they gave him a new heart disease drug, so the drug must not work.

Each conclusion is based on data. However, there are two problems. First, the data only represent one or two cases. Second, and more importantly, it is unclear whether these cases are actually representative of the population. Data collected in this haphazard fashion are called **anecdotal evidence**.

```{r}
#| echo: false
#| fig-align: "center"
#| fig-cap: "In February 2010, some media pundits cited one large snow storm as evidence against global warming. As comedian Jon Stewart pointed out, *It's one storm, in one region, of one country.*"
knitr::include_graphics("./figures/mnWinter.JPG")  
```

> **Anecdotal evidence**: Be careful of data collected haphazardly. Such evidence may be true and verifiable, but it may only represent extraordinary cases.

Anecdotal evidence typically is composed of unusual cases that we recall based on their striking characteristics. For instance, we are more likely to remember the two people we met who took 7 years to graduate than the six others who graduated in four years. Instead of looking at the most unusual cases, we should examine a sample of many cases that represent the population.

### Sampling from a population

We might try to estimate the time to graduation for Duke undergraduates in the last 5 years by collecting a sample of students. All graduates in the last 5 years represent the *population*, and graduates who are selected for review are collectively called the *sample*. In general, we always seek to *randomly* select a sample from a population. The most basic type of random selection is equivalent to how raffles are conducted. For example, in selecting graduates, we could write each graduate's name on a raffle ticket and draw 100 tickets. The selected names would represent a random sample of 100 graduates. This is illustrated in @fig-randsamp .

```{r}
#| label: fig-randsamp
#| echo: false
#| fig-cap: "In this graphic, five graduates are randomly selected from the population to be included in the sample."
#| 
set.seed(52)

plot(c(0, 2), c(0, 1.1), type = 'n', axes = F, xlab = "", ylab = "")
temp <- seq(0, 2*pi, 2*pi/100)
x <- 0.5 + 0.5*cos(temp)
y <- 0.5 + 0.5*sin(temp)
lines(x, y)

s <- matrix(runif(700), ncol = 2)
S <- matrix(NA, 350, 2)
j <- 0
for(i in 1:dim(s)[1]){
	if(sum((s[i,] - 0.5)^2) < 0.23){
		j <- j + 1
		S[j,] <- s[i,]
	}
}
points(S, col = COL[4, 3], pch = 20)
text(0.5, 1, 'all graduates', pos = 3)

set.seed(50)
N <- sample(j, 25)
lines((x - 0.5) / 2 + 1.5, (y - 0.5) / 2 + 0.5, pch = 20)

SS <- (S[N,] - 0.5) / 2 + 0.5
points(SS[c(2, 5, 11, 10, 12), 1] + 1, SS[c(2, 5, 11, 10, 12), 2], 
       col = COL[1, 2], pch = 20, cex = 1.5)
text(1.5, 0.75, 'sample', pos = 3)

for(i in c(2, 5, 11, 10, 12)){
	arrows(S[N[i], 1], S[N[i], 2], SS[i, 1] + 1 - 0.03, SS[i, 2], 
	       length = 0.08, col = COL[5], lwd = 1.5)
}

```

Why pick a sample randomly? Why not just pick a sample by hand? Consider the following scenario.

> **Example**:\
> Suppose we ask a student who happens to be majoring in nutrition to select several graduates for the study. What kind of students do you think she might collect? Do you think her sample would be representative of all graduates? [^overview-of-data-collection-principles-2]

[^overview-of-data-collection-principles-2]: Perhaps she would pick a disproportionate number of graduates from health-related fields. Or perhaps her selection would be well-representative of the population. When selecting samples by hand, we run the risk of picking a *biased* sample, even if that bias is unintentional or difficult to discern.

```{r}
#| label: fig-biased
#| echo: false
#| fig-cap: "Instead of sampling from all graduates equally, a nutrition major might inadvertently pick graduates with health-related majors disproportionately often."
#| 
set.seed(52)

plot(c(0, 2), c(0, 1.1), type = 'n', axes = F, xlab = "", ylab = "")
temp <- seq(0, 2*pi, 2*pi/100)
x <- 0.5 + 0.5*cos(temp)
y <- 0.5 + 0.5*sin(temp)
lines(x,y)

s <- matrix(runif(700), ncol = 2)
S <- matrix(NA, 350, 2)
j <- 0
sub <- rep(FALSE, 1000)
for(i in 1:dim(s)[1]){
	if(sum((s[i,] - 0.5)^2) < 0.23){
		j <- j + 1
		S[j,] <- s[i,]
	}
	if(sum((s[i,] - c(0.05, 0.18) - 0.5)^2) < 0.07){
		sub[j] <- TRUE
	}
}
points(S, col = COL[4, 4 - 2*sub], pch = 20)
text(0.5, 1, 'all graduates', pos = 3)
lines((x - 0.5)*2*sqrt(0.07) + 0.55, (y - 0.5)*2*sqrt(0.07) + 0.68)

set.seed(7)
N <- sample((1:j)[sub], 25)
lines((x - 0.5) / 2 + 1.5, (y - 0.5) / 2 + 0.5, pch = 20)

SS <- (S[N,] - 0.5) / 2 + 0.5
points(SS[c(2, 5, 7, 15), 1] + 1, SS[c(2, 5, 7, 15), 2], 
       col = COL[1,2], pch = 20, cex = 1.5)
text(1.5, 0.75, 'sample', pos = 3)

for(i in c(2, 5, 7, 15)){
	arrows(S[N[i], 1], S[N[i], 2], SS[i, 1] + 1 - 0.03, SS[i, 2], 
	       length = 0.08, col = COL[5], lwd = 1.5)
}
rect(0.143, 0.2, 0.952, 0.301, border = "#00000000", col = "#FFFFFF88")
rect(0.236, 0.301, 0.858, 0.403, border = "#00000000", col = "#FFFFFF88")
text(0.55, 0.5 + 0.18 - sqrt(0.07), 
     'graduates from\nhealth-related fields', pos = 1)

```

If someone was permitted to pick and choose exactly which graduates were included in the sample, it is entirely possible that the sample could be skewed to that person's interests, which may be entirely unintentional. This introduces **sampling bias** (see @fig-biased), where some individuals in the population are more likely to be sampled than others. Sampling randomly helps resolve this problem. The most basic random sample is called a **simple random sample**, which is equivalent to using a raffle to select cases. This means that each case in the population has an equal chance of being included and there is no implied connection between the cases in the sample.

Sometimes a simple random sample is difficult to implement and an alternative method is helpful. One such substitute is a **systematic sample**, where one case is sampled after letting a fixed number of others, say 10 other cases, pass by. Since this approach uses a mechanism that is not easily subject to personal biases, it often yields a reasonably representative sample. This book will focus on simple random samples since the use of systematic samples is uncommon and requires additional considerations of the context.

The act of taking a simple random sample helps minimize bias. However, bias can crop up in other ways. Even when people are picked at random, e.g. for surveys, caution must be exercised if the non-response is high. For instance, if only 30% of the people randomly sampled for a survey actually respond, and it is unclear whether the respondents are **representative**[^overview-of-data-collection-principles-3] of the entire population, the survey might suffer from **non-response bias**[^overview-of-data-collection-principles-4].

[^overview-of-data-collection-principles-3]: A representative sample accurately reflects the characteristics of the population.

[^overview-of-data-collection-principles-4]: Non-response bias is bias that can be introduced when subjects elect not to participate in a study. Often, the individuals that do participate are systematically different from the individuals who do not.

```{r}
#| label: fig-convsamp
#| echo: false
#| fig-cap: "Due to the possibility of non-response, surveys studies may only reach a certain group within the population. It is difficult, and often impossible, to completely fix this problem."

set.seed(52)

plot(c(0, 2), c(0, 1.1), type = 'n', axes = F, xlab = "", ylab = "")
temp <- seq(0, 2*pi, 2*pi/100)
x <- 0.5 + 0.5*cos(temp)
y <- 0.5 + 0.5*sin(temp)
lines(x, y)

s <- matrix(runif(700), ncol = 2)
S <- matrix(NA, 350, 2)
j <- 0
sub <- rep(FALSE, 1000)
for(i in 1:dim(s)[1]){
	if(sum((s[i, ] - 0.5)^2) < 0.23){
		j <- j + 1
		S[j, ] <- s[i, ]
	}
	if(sum((s[i, ] - c(-0.15, 0.05) - 0.5)^2) < 0.115){
		sub[j] <- TRUE
	}
}
points(S, col = COL[4, 4 - 2*sub], pch = 20)
text(0.5, 1, 'population of interest', pos = 3)
lines((x - 0.5)*2*sqrt(0.115) + 0.35, (y - 0.5)*2*sqrt(0.115) + 0.55)

set.seed(7)
N <- sample((1:j)[sub], 25)
lines((x - 0.5) / 2 + 1.5, (y - 0.5) / 2 + 0.5, pch = 20)

SS <- (S[N, ] - 0.5) / 2 + 0.5
points(SS[c(2, 5, 7, 15), 1] + 1, SS[c(2, 5, 7, 15), 2], 
       col = COL[1, 2], pch = 20, cex = 1.5)
text(1.5, 0.75, 'sample', pos = 3)

for(i in c(2, 5, 7, 15)){
	arrows(S[N[i], 1], S[N[i], 2], SS[i, 1] + 1 - 0.03, SS[i, 2], 
	       length = 0.08, col = COL[5], lwd = 1.5)
}
rect(0.145, 0.195, 0.775, 0.11, border = "#00000000", col = "#FFFFFF88")
rect(0.31, 0.018, 0.605, 0.11, border = "#00000000", col = "#FFFFFF88")
text(0.46, 0.5 + 0.06-sqrt(0.115), 
     'population actually\nsampled', pos = 1, cex = 0.8)


```

Another common pitfall is a **convenience sample**, where individuals who are easily accessible are more likely to be included in the sample, see @fig-convsamp. For instance, if a political survey is done by stopping people walking in the Bronx, it will not represent all of New York City. It is often difficult to discern what sub-population a convenience sample represents.

> **Exercise**:\
> We can easily access ratings for products, sellers, and companies through websites. These ratings are based only on those people who go out of their way to provide a rating. If 50% of online reviews for a product are negative, do you think this means that 50% of buyers are dissatisfied with the product?[^overview-of-data-collection-principles-5]

[^overview-of-data-collection-principles-5]: Answers will vary. From our own anecdotal experiences, we believe people tend to rant more about products that fell below expectations than rave about those that perform as expected. For this reason, we suspect there is a negative bias in product ratings on sites like Amazon. However, since our experiences may not be representative, we also keep an open mind.

### Explanatory and response variables

Consider the following question for the `county` data set:

Is federal spending, on average, higher or lower in counties with high rates of poverty?

If we suspect poverty might affect spending in a county, then poverty is the **explanatory** variable and federal spending is the **response** variable in the relationship.[^overview-of-data-collection-principles-6] If there are many variables, it may be possible to consider a number of them as explanatory variables.

[^overview-of-data-collection-principles-6]: Sometimes the explanatory variable is called the **independent** variable and the response variable is called the **dependent** variable. However, this becomes confusing since a *pair* of variables might be independent or dependent, so be careful and consider the context when using or reading these words.

> **Explanatory** and **response** variables\
> To identify the explanatory variable in a pair of variables, identify which of the two variables is suspected as explaining or causing changes in the other. In data sets with more than two variables, it is possible to have multiple explanatory variables. The response variable is the outcome or result of interest.

> **Caution**: Association does not imply causation. Labeling variables as *explanatory* and *response* does not guarantee the relationship between the two is actually causal, even if there is an association identified between the two variables. We use these labels only to keep track of which variable we suspect affects the other. We also use this language to help in our use of `R` and the formula notation.

In some cases, there is no explanatory or response variable. Consider the following question:

If homeownership in a particular county is lower than the national average, will the percent of multi-unit structures in that county likely be above or below the national average?

It is difficult to decide which of these variables should be considered the explanatory and response variable; i.e. the direction is ambiguous, so no explanatory or response labels are suggested here.

### Introducing observational studies and experiments

There are two primary types of data collection: observational studies and experiments.

Researchers perform an **observational study** when they collect data in a way that does not directly interfere with how the data arise. For instance, researchers may collect information via surveys, review medical or company records, or follow a **cohort**[^overview-of-data-collection-principles-7] of many similar individuals to study why certain diseases might develop. In each of these situations, researchers merely observe what happens. In general, observational studies can provide evidence of a naturally occurring association between variables, but by themselves, they cannot show a causal connection.

[^overview-of-data-collection-principles-7]: A cohort is a group of individuals who are similar in some way.

When researchers want to investigate the possibility of a causal connection, they conduct an **experiment**, a study in which the explanatory variables are assigned rather than observed. For instance, we may suspect administering a drug will reduce mortality in heart attack patients over the following year. To check if there really is a causal connection between the explanatory variable and the response, researchers will collect a sample of individuals and split them into groups. The individuals in each group are *assigned* a treatment. When individuals are *randomly* assigned to a treatment group, and we are *comparing* at least two treatments, the experiment is called a **randomized comparative experiment**. For example, each heart attack patient in the drug trial could be randomly assigned, perhaps by flipping a coin, into one of two groups: the first group receives a **placebo** (fake treatment) and the second group receives the drug. The case study at the beginning of the book is another example of an experiment, though that study did not employ a placebo. Math 359 is a course on the design and analysis of experimental data, DOE, at USAFA. In the Air Force, these types of experiments are an important part of test and evaluation. Many Air Force analysts are expert practitioners of DOE. In this book though, we will minimize our discussion of DOE.

> **Association** $\neq$ **Causation**\
> Again, association does not imply causation. In a data analysis, association does not imply causation, and causation can only be inferred from a randomized experiment. Although, a hot field is the analysis of causal relationships in observational data. This is important because consider cigarette smoking, how do we know it causes lung cancer? We only have observational data and clearly cannot do an experiment. We think analysts will be charged in the near future with using causal reasoning on observational data.
